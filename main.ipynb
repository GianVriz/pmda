{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Metodologies for Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n",
    "- Lorenzo Dell'Oro\n",
    "- Giovanni Toto\n",
    "- Gian Luca Vriz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>KEY IDEA AND OBJECTIVE OF THE PROJECT</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>LIBRARIES</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv                                   # 2\n",
    "import string                                # 2\n",
    "from src.preprocessing import preprocessing  # 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>INTRODUCTION TO DATA</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pre-processing of the corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>PRE-PROCESSING OF TEXTS</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to import the dataset from a file (txt/csv/...); this is an example with [UN General Debates corpus](https://www.kaggle.com/datasets/unitednations/un-general-debates):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_DOCS = 1000\n",
    "min_df = 10\n",
    "\n",
    "# Data type\n",
    "flag_split_by_paragraph = True  # whether to split documents by paragraph\n",
    "    \n",
    "# Read raw data (https://www.kaggle.com/datasets/unitednations/un-general-debates)\n",
    "print('reading raw data...')\n",
    "with open('./data/raw/un-general-debates.csv', encoding='utf-8-sig') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',', quotechar='\"')\n",
    "    line_count = 0\n",
    "    all_timestamps_ini = []\n",
    "    all_docs_ini = []\n",
    "    for row in csv_reader:\n",
    "        # skip header\n",
    "        if(line_count>0):\n",
    "            all_timestamps_ini.append(row[1])\n",
    "            all_docs_ini.append(row[3].encode(\"ascii\", \"ignore\").decode())\n",
    "        line_count += 1\n",
    "        if line_count==N_DOCS-1:  ###########\n",
    "            break                 ###########\n",
    "\n",
    "if flag_split_by_paragraph:\n",
    "    print('splitting by paragraphs...')\n",
    "    docs = []\n",
    "    timestamps = []\n",
    "    for dd, doc in enumerate(all_docs_ini):\n",
    "        splitted_doc = doc.split('.\\n')\n",
    "        for ii in splitted_doc:\n",
    "            docs.append(ii)\n",
    "            timestamps.append(all_timestamps_ini[dd])\n",
    "else:\n",
    "    docs = all_docs_ini\n",
    "    timestamps = all_timestamps_ini\n",
    "\n",
    "del all_docs_ini\n",
    "del all_timestamps_ini\n",
    "\n",
    "print('  number of documents: {}'.format(len(docs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction to pre-processing with gensim: [link](https://radimrehurek.com/gensim/auto_examples/core/run_core_concepts.html#from-strings-to-vectors)\n",
    "\n",
    "The real pre-processing starts here: in short, we want to get strings without strange characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation\n",
    "print('removing punctuation...')\n",
    "docs = [[w.lower().replace(\"’\", \" \").replace(\"'\", \" \").translate(str.maketrans('', '', string.punctuation + \"0123456789\")) for w in docs[doc].split()] for doc in range(len(docs))]\n",
    "docs = [[w for w in docs[doc] if len(w)>1] for doc in range(len(docs))]\n",
    "docs = [\" \".join(docs[doc]) for doc in range(len(docs))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we use `preprocessing` function contained in `src/preprocessing.py` module, which creates files compatible with *ETM* and *DETM*. We will use these files also to perform explorative analysis. Before launching the function, we need to import stopwords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read stopwords\n",
    "with open(\"./data/stops.txt\", \"r\") as f:\n",
    "    stopwords = f.read().split('\\n')\n",
    "# Pre-processing\n",
    "preprocessing(data_path=\"data/un-general-debates\", docs=docs, timestamps=timestamps, stopwords=stopwords,\n",
    "              min_df=min_df, max_df=0.7, data_split=[0.85, 0.1, 0.05], seed=28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**remark1:** `docs` and `timestamps` are two lists of strings containing the same number of elements; in particular, `docs` contains the documents of the corpus, `timestamps` their timestamps.\n",
    "\n",
    "**remark2:** The function also divides the corpus into train, test and validation set: below we will consider the training set for exploratory analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory analysis of the processed corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "EXPLORATORY ANALYSIS OF THE **TRAIN** CORPUS:\n",
    "\n",
    "- tabella con info corpus (num documenti, num timestamps, documenti per timestamp, ...)\n",
    "- distribuzione lunghezza documenti (numero parole)\n",
    "- parole più frequenti (word cloud)\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import vocabulary of the train set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.file_io import load_vocab\n",
    "word2id, id2word = load_vocab(\"data/un-general-debates/vocab.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we consider the train corpus only, i.e. we are interested in the following files generated by `preprocessing` function:\n",
    "- `bow_tr_tokens`: index of the different words observed in the documents of the train set;\n",
    "- `bow_tr_counts`: occurrences of the different words observed in the documents of the train set;\n",
    "- `bow_tr_timestamps`: timestamps of the documents of the train set;\n",
    "- `timestamps.txt`: different observed timestamps;\n",
    "- `vocab.txt`: vocabulary of the train set.\n",
    "\n",
    "**remark:** the first 3 files exist also for test and validation set, however they are not relevant to exploratory analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from scipy.io import loadmat\n",
    "path = os.path.join('data', 'un-general-debates', 'min_df_'+str(min_df))\n",
    "bow_tr_tokens = loadmat(os.path.join(path, 'bow_tr_tokens'))['tokens'].squeeze()\n",
    "bow_tr_counts = loadmat(os.path.join(path, 'bow_tr_counts'))['counts'].squeeze()\n",
    "bow_tr_timestamps = loadmat(os.path.join(path, 'bow_tr_timestamps'))['timestamps'].squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(bow_tr_timestamps))\n",
    "print(len(bow_tr_counts))\n",
    "print(len(bow_tr_tokens[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"print(bow_tr_timestamps)\n",
    "for i in range(8):\n",
    "    print(i, \"\\t\", bow_tr_tokens[i].shape, \"\\t\", bow_tr_counts[i].shape)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Embeddings and topic models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>INTRODUCTION TO MODEL ESTIMATION</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.i. Fitting embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>BRIEF DESCRIPTION OF THE DIFFERENT APPROACHES</font><br>\n",
    "<font color='blue'>EMBEDDING FITTING</font><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want the use the same embedding space for both *ETM* and *DETM*, so we first fit the word embeddings and then we provide them as input. In particular, we fit a simple *skipgram*; this implementation is an adaptation of this [code](https://github.com/adjidieng/ETM/blob/master/skipgram.py):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_bow = [docs[doc].split() for doc in range(len(docs))]  # list of list of strings (BoW representation)\n",
    "\n",
    "# fit embeddings\n",
    "from gensim.models import Word2Vec\n",
    "skipgram = Word2Vec(sentences=docs_bow, min_count=100, sg=1, size=100, iter=5, workers=5, negative=10, window=4)\n",
    "\n",
    "from src.file_io import save_embeddings\n",
    "save_embeddings(emb_model=skipgram, emb_file='data/un-general-debates_embeddings.txt', vocab=list(word2id.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.ii. Embedded Topic Model (ETM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>BRIEF DESCRIPTION OF THE MODEL</font><br>\n",
    "<font color='blue'>MODEL ESTIMATION</font><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have that:\n",
    "- `rho` contains the word embeddings (row=embedding)\n",
    "- `model.alphas.weight` contains the topic embeddings (row=embedding)\n",
    "- `beta` contains the topic-word distributions (row=distribution)\n",
    "- `theta` contains the document-topic distribution (row=distribution)\n",
    "\n",
    "**TO DO:** modify `main_ETM` function to make it return these quantities (when `mode='eval'`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following block allows to train *ETM*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from src.main_ETM import main_ETM\n",
    "main_ETM(dataset='un-general-debates', data_path='data/un-general-debates', save_path='results',\n",
    "         emb_file='data/un-general-debates_embeddings.txt', model_file='ETM_K50_un-general-debates', batch_size=2000,\n",
    "         mode='train', num_topics=50, train_embeddings=0, epochs=100, visualize_every=1000, tc=False, td=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following block allows to evaluate *ETM*, i.e.,\n",
    "- compute *topic coherence* on the top 10 words of each topic;\n",
    "- compute *topic diversity* on the top 25 words of each topic,\n",
    "- compute the ranking of the most used topics in the train corpus;\n",
    "- compute the top `num_words` words per topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from src.main_ETM import main_ETM\n",
    "main_ETM(dataset='un-general-debates', data_path='data/un-general-debates', save_path='results',\n",
    "         emb_file='data/un-general-debates_embeddings.txt', model_file='ETM_K50_un-general-debates', mode='eval',\n",
    "         load_from='results/ETM_K50_un-general-debates',\n",
    "         num_topics=50, train_embeddings=0, epochs=100, visualize_every=1000, num_words=10, tc=True, td=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.iii. Dynamic Embedded Topic Model (DETM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>BRIEF DESCRIPTION OF THE MODEL</font><br>\n",
    "<font color='blue'>MODEL ESTIMATION</font><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Memory problems:** DETM rquires too much memory!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting vocabulary ...\n",
      "Getting training data ...\n",
      "idx: 0/25\n",
      "idx: 20/25\n",
      "Getting validation data ...\n",
      "idx: 0/2\n",
      "Getting testing data ...\n",
      "idx: 0/3\n",
      "idx: 0/3\n",
      "idx: 0/3\n",
      "Getting embeddings ...\n",
      "\n",
      "\n",
      "=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*\n",
      "Training a Dynamic Embedded Topic Model on UN-GENERAL-DEBATES\n",
      "=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*\n",
      "\n",
      "DETM architecture: DETM(\n",
      "  (t_drop): Dropout(p=0.0, inplace=False)\n",
      "  (theta_act): ReLU()\n",
      "  (q_theta): Sequential(\n",
      "    (0): Linear(in_features=8604, out_features=800, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=800, out_features=800, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (mu_q_theta): Linear(in_features=800, out_features=50, bias=True)\n",
      "  (logsigma_q_theta): Linear(in_features=800, out_features=50, bias=True)\n",
      "  (q_eta_map): Linear(in_features=8554, out_features=200, bias=True)\n",
      "  (q_eta): LSTM(200, 200, num_layers=3)\n",
      "  (mu_q_eta): Linear(in_features=250, out_features=50, bias=True)\n",
      "  (logsigma_q_eta): Linear(in_features=250, out_features=50, bias=True)\n",
      ")\n",
      "Epoch: 1 .. batch: 10/242 .. LR: 0.005 .. KL_theta: 294207.74 .. KL_eta: 23201.18 .. KL_alpha: 45979771.64 .. Rec_loss: 14605606.36 .. NELBO: 60902787.64\n",
      "Epoch: 1 .. batch: 20/242 .. LR: 0.005 .. KL_theta: 160859.08 .. KL_eta: 12312.9 .. KL_alpha: 44757782.86 .. Rec_loss: 14572543.1 .. NELBO: 59503498.48\n",
      "Epoch: 1 .. batch: 30/242 .. LR: 0.005 .. KL_theta: 110469.57 .. KL_eta: 8455.46 .. KL_alpha: 43611710.45 .. Rec_loss: 14274025.06 .. NELBO: 58004660.65\n",
      "Epoch: 1 .. batch: 40/242 .. LR: 0.005 .. KL_theta: 84094.84 .. KL_eta: 6495.28 .. KL_alpha: 42493124.59 .. Rec_loss: 14337395.95 .. NELBO: 56921110.54\n",
      "Epoch: 1 .. batch: 50/242 .. LR: 0.005 .. KL_theta: 67825.48 .. KL_eta: 5309.77 .. KL_alpha: 41450238.2 .. Rec_loss: 14125751.71 .. NELBO: 55649124.94\n",
      "Epoch: 1 .. batch: 60/242 .. LR: 0.005 .. KL_theta: 56853.85 .. KL_eta: 4514.94 .. KL_alpha: 40437463.67 .. Rec_loss: 14293249.52 .. NELBO: 54792081.77\n",
      "Epoch: 1 .. batch: 70/242 .. LR: 0.005 .. KL_theta: 48981.88 .. KL_eta: 3944.87 .. KL_alpha: 39480036.51 .. Rec_loss: 14345650.3 .. NELBO: 53878613.46\n",
      "Epoch: 1 .. batch: 80/242 .. LR: 0.005 .. KL_theta: 43050.78 .. KL_eta: 3516.08 .. KL_alpha: 38559636.1 .. Rec_loss: 14496882.06 .. NELBO: 53103084.94\n",
      "Epoch: 1 .. batch: 90/242 .. LR: 0.005 .. KL_theta: 38448.39 .. KL_eta: 3182.05 .. KL_alpha: 37687100.29 .. Rec_loss: 14552168.13 .. NELBO: 52280898.81\n",
      "Epoch: 1 .. batch: 100/242 .. LR: 0.005 .. KL_theta: 34773.74 .. KL_eta: 2914.67 .. KL_alpha: 36853119.52 .. Rec_loss: 14556871.35 .. NELBO: 51447679.25\n",
      "Epoch: 1 .. batch: 110/242 .. LR: 0.005 .. KL_theta: 31737.35 .. KL_eta: 2695.79 .. KL_alpha: 36052077.96 .. Rec_loss: 14533748.1 .. NELBO: 50620259.17\n",
      "Epoch: 1 .. batch: 120/242 .. LR: 0.005 .. KL_theta: 29242.96 .. KL_eta: 2513.27 .. KL_alpha: 35284574.53 .. Rec_loss: 14537848.05 .. NELBO: 49854178.71\n",
      "Epoch: 1 .. batch: 130/242 .. LR: 0.005 .. KL_theta: 27127.82 .. KL_eta: 2358.91 .. KL_alpha: 34551286.37 .. Rec_loss: 14562984.3 .. NELBO: 49143757.31\n",
      "Epoch: 1 .. batch: 140/242 .. LR: 0.005 .. KL_theta: 25309.97 .. KL_eta: 2226.43 .. KL_alpha: 33850065.77 .. Rec_loss: 14549966.5 .. NELBO: 48427568.68\n",
      "Epoch: 1 .. batch: 150/242 .. LR: 0.005 .. KL_theta: 23758.0 .. KL_eta: 2111.63 .. KL_alpha: 33174233.66 .. Rec_loss: 14525548.6 .. NELBO: 47725651.92\n",
      "Epoch: 1 .. batch: 160/242 .. LR: 0.005 .. KL_theta: 22430.49 .. KL_eta: 2011.49 .. KL_alpha: 32527724.31 .. Rec_loss: 14617928.53 .. NELBO: 47170094.76\n",
      "Epoch: 1 .. batch: 170/242 .. LR: 0.005 .. KL_theta: 21235.38 .. KL_eta: 1922.4 .. KL_alpha: 31903283.94 .. Rec_loss: 14604755.75 .. NELBO: 46531197.4\n",
      "Epoch: 1 .. batch: 180/242 .. LR: 0.005 .. KL_theta: 20190.98 .. KL_eta: 1843.07 .. KL_alpha: 31303473.8 .. Rec_loss: 14598925.49 .. NELBO: 45924433.25\n",
      "Epoch: 1 .. batch: 190/242 .. LR: 0.005 .. KL_theta: 19276.81 .. KL_eta: 1772.36 .. KL_alpha: 30728437.65 .. Rec_loss: 14670983.66 .. NELBO: 45420470.43\n",
      "Epoch: 1 .. batch: 200/242 .. LR: 0.005 .. KL_theta: 18442.14 .. KL_eta: 1708.71 .. KL_alpha: 30173887.79 .. Rec_loss: 14641124.25 .. NELBO: 44835162.87\n",
      "Epoch: 1 .. batch: 210/242 .. LR: 0.005 .. KL_theta: 17692.8 .. KL_eta: 1651.01 .. KL_alpha: 29639132.84 .. Rec_loss: 14630930.94 .. NELBO: 44289407.55\n",
      "Epoch: 1 .. batch: 220/242 .. LR: 0.005 .. KL_theta: 17066.02 .. KL_eta: 1598.5 .. KL_alpha: 29124667.69 .. Rec_loss: 14666682.38 .. NELBO: 43810014.53\n",
      "Epoch: 1 .. batch: 230/242 .. LR: 0.005 .. KL_theta: 16491.89 .. KL_eta: 1550.38 .. KL_alpha: 28629994.6 .. Rec_loss: 14627371.83 .. NELBO: 43275408.64\n",
      "Epoch: 1 .. batch: 240/242 .. LR: 0.005 .. KL_theta: 15978.95 .. KL_eta: 1506.27 .. KL_alpha: 28149583.48 .. Rec_loss: 14642252.94 .. NELBO: 42809321.6\n",
      "****************************************************************************************************\n",
      "Epoch----->1 .. LR: 0.005 .. KL_theta: 15928.42 .. KL_eta: 1502.04 .. KL_alpha: 28102801.99 .. Rec_loss: 14636686.14 .. NELBO: 42756918.55\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 1.59 GiB (GPU 0; 4.00 GiB total capacity; 2.27 GiB already allocated; 538.28 MiB free; 141.60 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-26edd3851aad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m main_DETM(dataset='un-general-debates', data_path='data/un-general-debates', save_path='data',\n\u001b[0;32m      3\u001b[0m           \u001b[0memb_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'data/un-general-debates_embeddings.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m           num_topics=50, train_embeddings=0, epochs=50, visualize_every=1000, tc=True)\n\u001b[0m",
      "\u001b[1;32mD:\\pmda\\src\\main_DETM.py\u001b[0m in \u001b[0;36mmain_DETM\u001b[1;34m(dataset, data_path, emb_path, save_path, batch_size, num_topics, rho_size, emb_size, t_hidden_size, theta_act, train_embeddings, eta_nlayers, eta_hidden_size, delta, lr, lr_factor, epochs, mode, optimizer, seed, enc_drop, eta_dropout, clip, nonmono, wdecay, anneal_lr, bow_norm, num_words, log_interval, visualize_every, eval_batch_size, load_from, tc)\u001b[0m\n\u001b[0;32m    408\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mvisualize_every\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvisualize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_words\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 410\u001b[1;33m             \u001b[0mval_ppl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_completion_ppl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'val'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    411\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'val_ppl: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_ppl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    412\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mval_ppl\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mbest_val_ppl\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\pmda\\src\\main_DETM.py\u001b[0m in \u001b[0;36mget_completion_ppl\u001b[1;34m(source)\u001b[0m\n\u001b[0;32m    289\u001b[0m                     \u001b[0mtheta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_theta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meta_td\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormalized_data_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m                     \u001b[0malpha_td\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimes_batch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'torch.LongTensor'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 291\u001b[1;33m                     \u001b[0mbeta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_beta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha_td\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    292\u001b[0m                     \u001b[0mloglik\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtheta\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m                     \u001b[0mloglik\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloglik\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\pmda\\src\\detm.py\u001b[0m in \u001b[0;36mget_beta\u001b[1;34m(self, alpha)\u001b[0m\n\u001b[0;32m    182\u001b[0m             \u001b[0mlogit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrho\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m         \u001b[0mlogit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 184\u001b[1;33m         \u001b[0mbeta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    185\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pmda\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36msoftmax\u001b[1;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[0;32m   1228\u001b[0m         \u001b[0mdim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'softmax'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1229\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1230\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1231\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1232\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 1.59 GiB (GPU 0; 4.00 GiB total capacity; 2.27 GiB already allocated; 538.28 MiB free; 141.60 MiB cached)"
     ]
    }
   ],
   "source": [
    "from src.main_DETM import main_DETM\n",
    "main_DETM(dataset='un-general-debates', data_path='data/un-general-debates', save_path='data',\n",
    "          emb_path='data/un-general-debates_embeddings.txt', mode='train', batch_size=100,\n",
    "          num_topics=50, train_embeddings=0, epochs=50, visualize_every=1000, tc=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>INTRODUCTION ON HOW WE WANT TO COMPARE MODELS</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The idea is introduced very well in \"Topic modeling in embedding spaces\": let's copy from there!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.i. Quantitative analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>COMPUTATION OF VARIOUS METRICS AND CONSTRUCTION OF GRAPHS</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.ii. Qualitative analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>INTERPRETATION OF TOPICS AND DOCUMENT REPRESENTATION</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>FINAL REMARKS</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Dieng, A. B., Ruiz, F. J., & Blei, D. M. (2019). The dynamic embedded topic model. arXiv preprint arXiv:1907.05545. [Arxiv link](https://arxiv.org/abs/1907.05545)\n",
    "\n",
    "Dieng, A. B., Ruiz, F. J., & Blei, D. M. (2020). Topic modeling in embedding spaces. Transactions of the Association for Computational Linguistics, 8, 439-453. [ACM Anthology](https://aclanthology.org/2020.tacl-1.29/),  [Arxiv link](https://arxiv.org/abs/1907.04907)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pmda",
   "language": "python",
   "name": "pmda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
